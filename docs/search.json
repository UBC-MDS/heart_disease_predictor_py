[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Predicting Heart Disease from Cleveland Database",
    "section": "",
    "text": "In this project, we developed and evaluated several classification models to predict the presence of heart disease using the Cleveland Heart Disease dataset (Detrano et al. 1988), which includes various clinical features. We compared four models: Logistic Regression, Support Vector Classifier (SVC), Dummy Classifier (as a baseline), and Decision Tree Classifier. Logistic Regression performed the best, achieving high accuracy of 0.84 and providing interpretable coefficients that helped us understand the impact of each feature on heart disease prediction. The SVC also performed well but slightly lagged behind Logistic Regression in test accuracy with 0.82. The Dummy Classifier served as a baseline, emphasizing the need for more sophisticated models, while the Decision Tree Classifier showed reasonable performance but tended to overfit. Misclassifications were analyzed to identify potential feature engineering opportunities, and future work could include exploring alternative classifiers such as Random Forests. Additionally, incorporating probability estimates into predictions would enhance the model’s clinical usability, providing clinicians with more confidence in the results."
  },
  {
    "objectID": "index.html#data",
    "href": "index.html#data",
    "title": "Predicting Heart Disease from Cleveland Database",
    "section": "3.1 Data",
    "text": "3.1 Data\nFor this project, we will be using the Heart Disease UCI dataset created by R. Detrano, A. Jánosi, W. Steinbrunn, M. Pfisterer, J. Schmid, S. Sandhu, K. Guppy, S. Lee, and V. Froelicher at the Department of Medicine, Veterans Administration Medical Center, Long Beach, California (Detrano et al. 1988). It was sourced from the UC Irvine Machine Learning Repository (Detrano et al. 1988) and can be found here. The specific file used represents the Cleveland locality. The dataset contains 303 rows, with each row representing summary statistics for a particular patient, and 14 columns with 13 features and 1 target variable. The target variable is the diagnosis of heart disease (angiographic disease status), and the value 0 is for no diagnosis of heart disease and the value 1 is for the diagnosis of heart disease. The 13 features are as follows:\n\nAge\nSex\nChest pain type\nResting blood pressure\nSerum cholesterol\nFasting blood sugar\nResting electrocardiographic\nMaximum heart rate achieved\nExercise induced angina\nOldpeak = ST depression induced by exercise relative to rest\nThe slope of the peak exercise ST segment\nNumber of major vessels\nThalassemia blood disorder\n\nThey are encoded in the dataset as follows:\n\n#3 (age)\n#4 (sex)\n#9 (cp)\n#10 (trestbps)\n#12 (chol)\n#16 (fbs)\n#19 (restecg)\n#32 (thalach)\n#38 (exang)\n#40 (oldpeak)\n#41 (slope)\n#44 (ca)\n#51 (thal)\n#58 (num) (the predicted attribute)"
  },
  {
    "objectID": "index.html#preprocessing",
    "href": "index.html#preprocessing",
    "title": "Predicting Heart Disease from Cleveland Database",
    "section": "3.2 Preprocessing",
    "text": "3.2 Preprocessing\nThe preprocessing steps are crucial for preparing the heart disease dataset for analysis and model training. This section outlines the steps taken to clean and transform the raw data before it is split into training and test datasets.\nFirstly, directories are created to store raw and processed data. If the directories do not already exist, they are created programmatically.\nNext, the heart disease dataset is downloaded as a ZIP file from the UCI Machine Learning Repository. Once downloaded, the ZIP file is extracted to the raw directory.\nAfter extraction, the dataset is read into a Pandas DataFrame. The column names are defined manually, as the dataset does not include a header row. At this point, it was noted that the raw dataset uses the string ‘?’ to represent missing values. These values are replaced with NaN to facilitate proper handling during further analysis.\nAs briefly mentioned in the above section, the target variable, num, represents the presence or absence of heart disease. The original values of num range from 0 to 4, where any value greater than 1 indicates the presence of heart disease. To simplify the analysis, all values greater than 1 are mapped to 1 (i.e., indicating the presence of heart disease).\nFinally, to prepare the dataset for model training and evaluation, it is split into training and test subsets. The split is done in a 70/30 ratio, with stratification to ensure that the distribution of the target variable num is preserved in both subsets. The resulting training and test sets are then saved as CSV files for future use such as in the next steps, which will involve analyzing the data, training models, and assessing their performance."
  },
  {
    "objectID": "index.html#analysis",
    "href": "index.html#analysis",
    "title": "Predicting Heart Disease from Cleveland Database",
    "section": "3.3 Analysis",
    "text": "3.3 Analysis\nIn this project, we used the Logistic Regression, SVC, Decision Tree, and Dummy Classifier as a baseline to build a classification model aimed at predicting the presence of heart disease based on clinical features. We used all available features from the dataset, excluding some variables related to the error of certain measurements. The data was split into a training set (70%) and a test set (30%). To choose the best value for the hyperparameter k, we used 5-fold cross-validation, with accuracy as the classification metric. We also standardized the data before fitting the model to ensure the features were on a similar scale. The analysis was carried out using Python, with the following libraries: NumPy, Pandas, scikit-learn, and Matplotlib."
  },
  {
    "objectID": "index.html#discussion",
    "href": "index.html#discussion",
    "title": "Predicting Heart Disease from Cleveland Database",
    "section": "4.1 Discussion",
    "text": "4.1 Discussion\n\n\n\n\nTable 1: Baseline Model CV Results\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfit_time\nscore_time\ntest_score\ntrain_score\n\n\n\n\nDummy\n0.009 (+/- 0.003)\n0.005 (+/- 0.003)\n0.543 (+/- 0.007)\n0.542 (+/- 0.002)\n\n\nDecision tree\n0.011 (+/- 0.003)\n0.003 (+/- 0.004)\n0.713 (+/- 0.048)\n1.000 (+/- 0.000)\n\n\nSVC\n0.010 (+/- 0.003)\n0.005 (+/- 0.002)\n0.844 (+/- 0.043)\n0.929 (+/- 0.017)\n\n\nLogistic Regression\n0.012 (+/- 0.001)\n0.005 (+/- 0.002)\n0.849 (+/- 0.027)\n0.889 (+/- 0.015)\n\n\n\n\n\n\n\n\n\n\n\n\nTable 2: Best Model CV Results\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfit_time\nscore_time\ntest_score\ntrain_score\n\n\n\n\nDecision Tree\n0.012 (+/- 0.001)\n0.004 (+/- 0.003)\n0.778 (+/- 0.037)\n0.960 (+/- 0.014)\n\n\nSVC\n0.008 (+/- 0.003)\n0.005 (+/- 0.003)\n0.849 (+/- 0.040)\n0.875 (+/- 0.007)\n\n\nLogistic Regression\n0.012 (+/- 0.001)\n0.006 (+/- 0.001)\n0.858 (+/- 0.053)\n0.881 (+/- 0.009)\n\n\n\n\n\n\n\n\nAfter doing checking on the baseline (Table 1) we proceed to do the cross-validation. In the final cross-validation results (Table 2), both the best SVC and best Logistic Regression achieve excellent test scores. The small gap between their training and test scores suggests that both models generalize well, with minimal overfitting. However, Logistic Regression has a smaller gap between training and test scores (0.023) compared to SVC (0.026), suggesting that it might generalize slightly better than SVC.\n\n\n\n\nTable 3: Test Score Results\n\n\n\n\n\n\n\nModel\nAccuracy\n\n\n\n\n0\nSVC fitted\n0.82\n\n\n1\nLogistic Regression fitted\n0.84\n\n\n\n\n\n\n\n\nThis is further confirmed by the test scores Table 3, which show that Logistic Regression slightly outperforms SVC on unseen data.\n\n\n\n\nTable 4: Detailed Coefficients for Logistic Regression\n\n\n\n\n\n\n\nFeature\nCoefficient\n\n\n\n\n0\npipeline-1__ca\n0.674653\n\n\n1\nonehotencoder__cp_4.0\n0.614785\n\n\n2\npipeline-2__thal_7.0\n0.450091\n\n\n3\nstandardscaler__oldpeak\n0.400388\n\n\n4\nonehotencoder__exang_1.0\n0.323725\n\n\n5\nonehotencoder__sex_1.0\n0.297677\n\n\n6\nonehotencoder__slope_2.0\n0.275565\n\n\n7\nstandardscaler__trestbps\n0.253341\n\n\n8\nonehotencoder__restecg_2.0\n0.168724\n\n\n9\nonehotencoder__fbs_0.0\n0.161019\n\n\n10\nstandardscaler__age\n0.0274616\n\n\n11\nstandardscaler__chol\n0.0143758\n\n\n12\npipeline-2__thal_6.0\n0.00637277\n\n\n13\nonehotencoder__restecg_1.0\n-0.00791221\n\n\n14\nonehotencoder__cp_2.0\n-0.055756\n\n\n15\nonehotencoder__slope_3.0\n-0.124035\n\n\n16\nonehotencoder__slope_1.0\n-0.15156\n\n\n17\nonehotencoder__restecg_0.0\n-0.160842\n\n\n18\nonehotencoder__fbs_1.0\n-0.161049\n\n\n19\nonehotencoder__cp_3.0\n-0.245399\n\n\n20\nonehotencoder__sex_0.0\n-0.297707\n\n\n21\nonehotencoder__cp_1.0\n-0.31366\n\n\n22\nonehotencoder__exang_0.0\n-0.323755\n\n\n23\nstandardscaler__thalach\n-0.406858\n\n\n24\npipeline-2__thal_3.0\n-0.456493\n\n\n\n\n\n\n\n\nTo better understand the relationship between each feature and heart disease presence, we examine the coefficients obtained from the logistic regression model (Table 4). Each coefficient indicates how the corresponding feature influences the likelihood of heart disease. Positive coefficients suggest that as the feature increases, the likelihood of having heart disease increases as well, while negative coefficients suggest the opposite.\n\n\n\n\n\n\nFigure 5: Coefficient Table for Logistic Regression\n\n\n\nIn Figure 5, we can see that features like ca, oldpeak, and trestbps have relatively high positive coefficients, meaning they strongly influence the prediction of heart disease. This makes sense, as research shows that high blood pressure is one of the most important causes of heart disease (Fuchs and Whelton 2020). For oldpeak specifically, research shows that ST depression during exercise is linked to higher risk of heart disease(Carlen et al. 2019). In contrast, features like thalach have large negative coefficients, suggesting they are linked to a lower likelihood of heart disease. Features like age and chol, however, show little impact, as their coefficients are close to zero.\nInterestingly, females (sex = 0) are more likely to be free of heart disease, as indicated by the large negative coefficient for onehotencoder__sex_0.0. In contrast, males (sex = 1) are more likely to have heart disease, as reflected by the high positive coefficient for onehotencoder__sex_1.0. This is supported by Regitz-Zagrosek and Gebhard (2023), which highlights how biological sex differences, such as premenopausal women having a relative protection from coronary artery disease.\nHowever, there are some limitations of this study. First of all, as categorical features were split into multiple binary columns, interpreting the coefficients for these encoded variables can be tricky. It can be difficult to directly correlate the coefficients with the original feature, and whether this approach is reasonable should also be questioned.\nAdditionally, while the model’s coefficients offer useful insights, they should be taken with caution. Further exploration into feature relationships and more advanced modeling techniques might be required to better understand the complexities of predicting heart disease.\n\n\n\n\nTable 5: Misclassified Examples\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nage\nsex\ncp\ntrestbps\nchol\nfbs\nrestecg\nthalach\nexang\noldpeak\nslope\nca\nthal\nTrue Label\nPredicted Label\n\n\n\n\n0\n64\n0\n4\n130\n303\n0\n0\n122\n0\n2\n2\n2\n3\n0\n1\n\n\n1\n48\n1\n2\n110\n229\n0\n0\n168\n0\n1\n3\n0\n7\n1\n0\n\n\n2\n59\n1\n1\n160\n273\n0\n2\n125\n0\n0\n1\n0\n3\n1\n0\n\n\n3\n58\n1\n4\n100\n234\n0\n0\n156\n0\n0.1\n1\n1\n7\n1\n0\n\n\n4\n64\n1\n3\n140\n335\n0\n0\n158\n0\n0\n1\n0\n3\n1\n0\n\n\n\n\n\n\n\n\nFrom Table 5, we can see that false Positives (e.g., index 0): Predicted as 1.0 (positive for heart disease), but true label is 0.0. This individual has a high cholesterol level (chol = 303.0), moderate oldpeak (oldpeak = 2.0), and significant ca = 2.0, which might make the model lean toward predicting heart disease incorrectly.\nFalse Negatives (e.g., indices 1, 2, 3, 4): Predicted as 0 (no heart disease), but true label is 1. Many of these cases involve features like high thalach (e.g., 168.0, 158.0) and slope = 3.0 or 1.0, which the model might not weigh heavily enough.\nOverall the Logistic Regression model performs well and could be useful as a first-pass screening tool in a clinical setting, but there are ways we can make it even better. First, we can take a closer look at the misclassified examples and compare them to correctly classified ones. This could help us identify features or patterns the model struggles with and guide us in improving the features or adding new ones that capture important relationships.\nNext, we could test other classifiers to see if they perform better. For example, Random Forests are good at handling feature interactions automatically, which could help improve accuracy.\nFinally, instead of just giving a prediction, the model could provide a probability for each class. This would help clinicians understand how confident the model is in its predictions. For low-confidence cases, additional tests or evaluations could be done to avoid mistakes.\nThese changes could make the model even more accurate and useful in practice."
  }
]