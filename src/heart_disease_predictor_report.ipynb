{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d31e1e6e-d82f-4f7e-8fb5-684d4927cbf9",
   "metadata": {},
   "source": [
    "# Predicting Heart Disease from Cleveland Database  \n",
    "\n",
    "Authors: Albert C. Halim, Archer Liu, Stephanie Wu, & Ziyuan Zhao  \n",
    "Date: November 18, 2024  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142189f4-a52a-452f-a217-7f46fb8e17e4",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "In this project, we developed classification models using the Cleveland Heart Disease dataset to predict the presence of heart disease based on various clinical measurements. We evaluated the performance of four models: Support Vector Classifier (SVC), Linear Regression (adapted for classification), a Dummy Classifier (as a baseline), and a Decision Tree Classifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5665ab-8891-4117-8d10-537e71e4a391",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc68df8-84fc-49ee-9e15-ead93acb9594",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b16c23e-115a-42fb-ade5-35037c855613",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c06cb6-f1ad-481e-9a3b-332aa7f782a5",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f80b24-1d99-4577-9aa1-3a8a7b7305f9",
   "metadata": {},
   "source": [
    "## Results & Discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a83167ff-61fe-4095-83ff-362ff229dca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File handling\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "# Data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn import set_config\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "# Machine Learning\n",
    "from scipy.stats import expon, lognorm, loguniform, randint, uniform, norm\n",
    "from sklearn.model_selection import  RandomizedSearchCV, cross_val_score, cross_validate\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Scoring Metrics\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, make_scorer, f1_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7815f82-902a-4f97-a036-df7451745342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the directory if it doesn't exist\n",
    "raw_dir = \"../data/raw\"\n",
    "if not os.path.exists(raw_dir):\n",
    "    os.makedirs(raw_dir)\n",
    "\n",
    "# Download data as zip\n",
    "url = \"https://archive.ics.uci.edu/static/public/45/heart+disease.zip\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Save the zip file to the specified directory\n",
    "zip_path = os.path.join(raw_dir, \"heart+disease.zip\")\n",
    "with open(zip_path, 'wb') as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "# Extract the contents of the zip file\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(raw_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec4badea-d877-4da7-b54e-ce0fa7be76dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "colnames = [\n",
    "    \"age\",       \n",
    "    \"sex\",       \n",
    "    \"cp\",        \n",
    "    \"trestbps\",  \n",
    "    \"chol\",      \n",
    "    \"fbs\",       \n",
    "    \"restecg\",   \n",
    "    \"thalach\",   \n",
    "    \"exang\",     \n",
    "    \"oldpeak\",   \n",
    "    \"slope\",     \n",
    "    \"ca\",        \n",
    "    \"thal\",      \n",
    "    \"num\"  \n",
    "]\n",
    "\n",
    "heart_disease = pd.read_csv(\"../data/raw/processed.cleveland.data\", names=colnames, header=None)\n",
    "# Replace missing values with nan for ease of computational handling\n",
    "heart_disease.replace('?', np.nan, inplace=True)\n",
    "# heart_disease = heart_disease.dropna()\n",
    "# Update the target variable 'num' (map values greater than 1 to 1)\n",
    "heart_disease['num'] = heart_disease['num'].apply(lambda x: 1 if x > 1 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f410924-5add-4cee-a0ff-e96602683aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale and split into train & test\n",
    "np.random.seed(522)\n",
    "set_config(transform_output=\"pandas\")\n",
    "\n",
    "# Create the split\n",
    "heart_disease_train, heart_disease_test = train_test_split(\n",
    "    heart_disease, train_size=0.70, stratify=heart_disease[\"num\"]\n",
    ")\n",
    "# Create the directory if it doesn't exist\n",
    "processed_dir = \"../data/processed\"\n",
    "if not os.path.exists(processed_dir):\n",
    "    os.makedirs(processed_dir)\n",
    "heart_disease_train.to_csv(\"../data/processed/heart_disease_train.csv\")\n",
    "heart_disease_test.to_csv(\"../data/processed/heart_disease_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc6f9963-7730-4261-b810-aad43488f50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_pipeline = make_pipeline(\n",
    "    SimpleImputer(strategy=\"most_frequent\"),\n",
    "    StandardScaler()\n",
    ")\n",
    "\n",
    "thal_pipeline = make_pipeline(\n",
    "    SimpleImputer(strategy=\"most_frequent\"),\n",
    "    OneHotEncoder(sparse_output=False)\n",
    ")\n",
    "\n",
    "heart_disease_preprocessor = make_column_transformer(\n",
    "    (ca_pipeline, ['ca']),  # Apply imputation and scaling to 'ca'\n",
    "    (thal_pipeline, ['thal']),  # Apply imputation and encoding to 'thal'\n",
    "    (OneHotEncoder(sparse_output=False), ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope']),\n",
    "    (StandardScaler(), [\"age\", \"trestbps\", \"chol\", \"thalach\", \"oldpeak\"]),\n",
    "    remainder='passthrough',\n",
    "    verbose_feature_names_out=True\n",
    ")\n",
    "\n",
    "heart_disease_preprocessor.fit(heart_disease_train)\n",
    "scaled_heart_disease_train = heart_disease_preprocessor.transform(heart_disease_train)\n",
    "scaled_heart_disease_test = heart_disease_preprocessor.transform(heart_disease_test)\n",
    "\n",
    "scaled_heart_disease_train.to_csv(\"../data/processed/scaled_heart_disease_train.csv\")\n",
    "scaled_heart_disease_test.to_csv(\"../data/processed/scaled_heart_disease_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3340546f-eccb-4ab4-a9d6-805ecde21aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = heart_disease_train.drop(columns=['num'])\n",
    "y_train = heart_disease_train['num']\n",
    "X_test = heart_disease_test.drop(columns=['num'])\n",
    "y_test = heart_disease_test['num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d876c40-eb35-463b-b500-d75e9adcdc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomized_search(X_train, y_train, model, param_dist, n_iter=100, cv=5, random_state=123):\n",
    "    \"\"\"\n",
    "    Performs RandomizedSearchCV on the specified model and returns the best model.\n",
    "    \n",
    "    Parameters:\n",
    "    X_train : DataFrame\n",
    "        Training features\n",
    "    y_train : Series\n",
    "        Training labels\n",
    "    model : estimator\n",
    "        The model to be tuned\n",
    "    param_dist : dict\n",
    "        Hyperparameter distribution for RandomizedSearchCV\n",
    "    n_iter : int, optional, default=100\n",
    "        Number of iterations for RandomizedSearchCV\n",
    "    cv : int, optional, default=5\n",
    "        Number of cross-validation folds\n",
    "    random_state : int, optional, default=123\n",
    "        Random seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "    best_model : estimator\n",
    "        The best model after RandomizedSearchCV\n",
    "    \"\"\"\n",
    "    # Perform RandomizedSearchCV\n",
    "    random_search = RandomizedSearchCV(model, param_distributions=param_dist,\n",
    "                                       n_iter=n_iter, cv=cv, n_jobs=-1, random_state=random_state,\n",
    "                                       return_train_score=True)\n",
    "    \n",
    "    # Fit the model\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    # Return the best model found by RandomizedSearchCV\n",
    "    return random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8035689a-68a1-4755-a713-bab583b196d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is taken from UBC 571 Course\n",
    "def mean_std_cross_val_scores(model, X_train, y_train, **kwargs):\n",
    "    \"\"\"\n",
    "    Returns mean and std of cross validation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model :\n",
    "        scikit-learn model\n",
    "    X_train : numpy array or pandas DataFrame\n",
    "        X in the training data\n",
    "    y_train :\n",
    "        y in the training data\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "        pandas Series with mean scores from cross_validation\n",
    "    \"\"\"\n",
    "\n",
    "    scores = cross_validate(model, X_train, y_train, **kwargs)\n",
    "\n",
    "    mean_scores = pd.DataFrame(scores).mean()\n",
    "    std_scores = pd.DataFrame(scores).std()\n",
    "    out_col = []\n",
    "\n",
    "    for i in range(len(mean_scores)):\n",
    "        out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores.iloc[i], std_scores.iloc[i])))\n",
    "\n",
    "    return pd.Series(data=out_col, index=mean_scores.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99f0ca5f-0efa-42f0-86b8-73297c6b1e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dummy</th>\n",
       "      <td>0.018 (+/- 0.003)</td>\n",
       "      <td>0.011 (+/- 0.002)</td>\n",
       "      <td>0.543 (+/- 0.007)</td>\n",
       "      <td>0.542 (+/- 0.002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.017 (+/- 0.001)</td>\n",
       "      <td>0.009 (+/- 0.001)</td>\n",
       "      <td>0.844 (+/- 0.043)</td>\n",
       "      <td>0.929 (+/- 0.017)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                fit_time         score_time         test_score  \\\n",
       "Dummy  0.018 (+/- 0.003)  0.011 (+/- 0.002)  0.543 (+/- 0.007)   \n",
       "SVC    0.017 (+/- 0.001)  0.009 (+/- 0.001)  0.844 (+/- 0.043)   \n",
       "\n",
       "             train_score  \n",
       "Dummy  0.542 (+/- 0.002)  \n",
       "SVC    0.929 (+/- 0.017)  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict = {}\n",
    "models = {\n",
    "    \"Dummy\": DummyClassifier(random_state=123),\n",
    "    \"SVC\": SVC(random_state=123)\n",
    "}\n",
    "\n",
    "for model in models.items():\n",
    "    pipe = make_pipeline(heart_disease_preprocessor, model[1])\n",
    "    results_dict[model[0]] = mean_std_cross_val_scores(\n",
    "        pipe, X_train, y_train, cv=5, return_train_score=True\n",
    "    )\n",
    "\n",
    "income_pred_results_df = pd.DataFrame(results_dict).T\n",
    "income_pred_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e49e8d8-750f-450b-8b45-420e1c208aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Best Model Train Accuracy Score:  0.8584905660377359\n"
     ]
    }
   ],
   "source": [
    "svc_param = {\n",
    "    \"gamma\": loguniform(1e-4, 1e2),\n",
    "    \"C\": loguniform(1e-4, 1e2),\n",
    "    \"class_weight\": [None, \"balanced\"]\n",
    "}\n",
    "\n",
    "best_svc_model = randomized_search(X_train, y_train, SVC(random_state=123), svc_param)\n",
    "\n",
    "# Calculate the train score (accuracy on training data)\n",
    "train_score = best_svc_model.score(X_train, y_train)\n",
    "print(\"SVC Best Model Train Accuracy Score: \", train_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51060789-48e6-4a60-b4c0-c15d2ad6d7a7",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a9a46d-425b-44c3-9e98-7aa5aa78ae5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
